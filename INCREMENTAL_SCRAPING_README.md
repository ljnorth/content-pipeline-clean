# Incremental Scraping System ðŸ”„

## Overview

The **Incremental Scraping System** is like having a smart assistant that only brings you NEW magazines instead of bringing the entire magazine collection every time! ðŸ“š

Instead of re-scraping ALL content from ALL accounts every time you run the pipeline, this system:
- **ðŸ†• New Accounts**: Scrapes up to 75 posts (full scraping)
- **ðŸ”„ Existing Accounts**: Only scrapes NEW posts since the last pipeline run
- **âš¡ Efficiency**: Saves time, API calls, and prevents duplicate content

## How It Works (Simple Explanation)

Think of it like checking your mailbox:

1. **First Time** (New Account): Get all the mail from the last few weeks âœ‰ï¸
2. **Every Day After** (Existing Account): Only get the NEW mail since yesterday ðŸ“®
3. **Smart Detection**: The system remembers what mail you already have ðŸ§ 

## Technical Implementation

### 1. Database Tracking
```sql
-- accounts table tracks when each account was last scraped
accounts (
  username TEXT,
  last_scraped TIMESTAMPTZ,
  ...
)

-- posts table has unique post_id to prevent duplicates
posts (
  post_id TEXT UNIQUE,
  username TEXT,
  post_timestamp TIMESTAMPTZ,
  ...
)
```

### 2. Account Processing Logic
```javascript
// AccountProcessor determines scraping strategy
for (const account of accounts) {
  if (account.isNew) {
    // New account: scrape up to 75 posts
    strategy = "full_scrape";
  } else {
    // Existing account: check for new posts only
    strategy = "incremental_scrape";
    existingPostIds = getExistingPostIds(account.username);
  }
}
```

### 3. ContentAcquirer Incremental Logic
```javascript
// For existing accounts
async scrapeIncrementalPosts(username, account) {
  // Get list of posts we already have
  const existingPostIds = await db.getExistingPostIds(username);
  
  // Check recent posts from TikTok
  const recentPosts = await scrapeBatch(username, RECENT_POSTS);
  
  // Filter out posts we already have
  const newPosts = recentPosts.filter(post => 
    !existingPostIds.includes(post.post_id)
  );
  
  return newPosts; // Only return truly NEW posts
}
```

## Benefits

### âš¡ Speed & Efficiency
- **Faster Pipeline Runs**: Only processes new content
- **Reduced API Usage**: Fewer calls to TikTok scraping service
- **Lower Costs**: Less processing time and API calls

### ðŸŽ¯ Accuracy
- **No Duplicates**: Prevents the same post from being stored twice
- **Up-to-Date**: Always gets the latest content without redundancy
- **Smart Detection**: Automatically knows what's new vs existing

### ðŸ“Š Scalability
- **Handles Growth**: As you add more accounts, existing ones don't slow down
- **Efficient at Scale**: 100 accounts with incremental is faster than 10 accounts with full scraping

## Usage Examples

### Scenario 1: Adding Your First Account
```
Account: @fashion_influencer (NEW)
Strategy: Full scrape (up to 75 posts)
Result: 67 new posts scraped âœ…
```

### Scenario 2: Re-running Pipeline on Existing Account
```
Account: @fashion_influencer (EXISTING - 67 posts in DB)
Strategy: Incremental scrape
API Check: Recent 25 posts from TikTok
Filter: 22 posts already in DB, 3 posts are new
Result: 3 new posts scraped âœ…
Time Saved: 95% faster than re-scraping all 67 posts!
```

### Scenario 3: Mixed Account List
```
Pipeline Run with 10 Accounts:
- 2 New accounts: Full scrape (150 total new posts)
- 8 Existing accounts: Incremental (23 total new posts)
Total: 173 posts vs 750 posts (if full scraping all)
Efficiency Gain: 77% reduction in scraping volume!
```

## Pipeline Integration

### All Pipeline Types Support Incremental
- **Sequential Pipeline** (`npm run pipeline`): Uses incremental scraping
- **Fast Pipeline** (`npm run fast`): Uses incremental scraping with concurrent processing
- **Batch Pipeline** (`npm run batch`): Uses incremental scraping with batch API processing

### Automatic Detection
No configuration needed! The system automatically:
1. Detects new vs existing accounts
2. Chooses the right scraping strategy
3. Filters out duplicate content
4. Updates the `last_scraped` timestamp

## Testing the System

### 1. Test Incremental Logic
```bash
node test-incremental-scraping.js
```

This shows:
- Which accounts are new vs existing
- How many posts each account currently has
- What scraping strategy would be used
- Expected efficiency gains

### 2. Run with Incremental (Default)
```bash
npm run pipeline
# or
npm run fast
# or
npm run batch
```

All pipelines now use incremental scraping by default!

## Monitoring Incremental Efficiency

### Pipeline Logs Show Efficiency
```
ðŸŽ‰ INCREMENTAL SCRAPING COMPLETE:
   ðŸ“Š Total accounts: 28
   ðŸ†• New accounts: 3
   ðŸ”„ Existing accounts: 25
   ðŸŽ¯ New posts scraped: 47
   âš¡ Efficiency: Only scraped new content!
```

### Account-Level Details
```
ðŸ”„ EXISTING ACCOUNT: Checking for new posts for @username (127 posts already saved)
ðŸ“¦ Checking batch 1 for new posts (offset: 0)
   ðŸ“Š Batch results: 25 scraped, 23 duplicates, 2 new
âœ… Found 2 new posts for @username
```

## Best Practices

### 1. Regular Pipeline Runs
- **Daily/Weekly**: Run pipeline regularly to catch new posts
- **Incremental Benefit**: More frequent runs = smaller incremental batches = faster processing

### 2. Account Management
- **Add Gradually**: Add new accounts over time rather than bulk-adding
- **Monitor Activity**: Accounts that post frequently will benefit most from incremental

### 3. Performance Optimization
- **Check Logs**: Monitor efficiency gains in pipeline logs
- **Balance Frequency**: Find the right balance between freshness and processing cost

## Database Schema Requirements

### Required Columns (Auto-created)
```sql
-- accounts table
ALTER TABLE accounts ADD COLUMN last_scraped TIMESTAMPTZ;

-- posts table (post_id must be unique)
ALTER TABLE posts ADD CONSTRAINT posts_post_id_unique UNIQUE (post_id);
```

### New Helper Methods
```javascript
// SupabaseClient methods for incremental support
async getExistingPostIds(username)     // Get list of existing post IDs
async getLatestPostTimestamp(username) // Get timestamp of newest post
async getPostCount(username)           // Get total post count for account
```

## Troubleshooting

### Q: Pipeline still seems slow
**A**: Check logs for "INCREMENTAL SCRAPING COMPLETE" summary. If you see high numbers of new accounts, that's expected (new accounts need full scraping).

### Q: Missing new posts
**A**: The system checks the most recent posts first. Very new posts should be caught immediately. Older posts (beyond the incremental window) might be missed but can be caught by running a full pipeline reset.

### Q: Want to force full re-scraping
**A**: Clear the `last_scraped` timestamp for specific accounts:
```sql
UPDATE accounts SET last_scraped = NULL WHERE username = 'account_name';
```

## Migration from Full Scraping

### Automatic Migration âœ…
- **No Action Needed**: Existing accounts automatically use incremental
- **Backward Compatible**: All existing data remains intact
- **Immediate Benefits**: Next pipeline run will be faster

### Performance Improvement Timeline
- **First Run**: Same speed (establishes baseline)
- **Second Run**: 50-80% faster (depends on new content ratio)
- **Ongoing Runs**: 80-95% faster (as accounts stabilize)

---

## Summary

The Incremental Scraping System transforms your fashion pipeline from a "download everything" approach to a smart "only get what's new" system. This means:

- âš¡ **Faster pipeline runs**
- ðŸ’° **Lower API costs** 
- ðŸŽ¯ **No duplicate content**
- ðŸ“ˆ **Better scalability**

The system works automatically - no configuration needed. Just run your pipeline as normal and enjoy the efficiency gains! 